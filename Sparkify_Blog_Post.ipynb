{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparkify - \"churning\" through data #\n",
    "\n",
    "*by Peter Staunton, Data Science Enthusiast*\n",
    "<br/>\n",
    "\n",
    "<img width=\"200\" src=\"https://stannnman.github.io/sparkify_screenshot.png\"/>\n",
    "    \n",
    "Retention of customers is critical to the health of all businesses. Churn, the loss of customers, can have a negative effect and companies will often invest in efforts to reduce churn. To this end, it helps if the business can identify those customers who are most likely to churn and focus their resources on this smaller cohort to incentivise them to stay.\n",
    "\n",
    "This project explores how data science is used to perform churn prediction on a data set from a hypothetical business called \"**Sparkify**\", a subscription music listening service. I chose this as my [Data Science Nanodegree](https://udacity.com/course/data-scientist-nanodegree--nd025) capstone project because I was keen to learn and apply pySpark, a technology for scalable data science that is widely used in industry today.\n",
    "\n",
    "The objective here is to use pySpark to take the sample data set through the full end-to-end lifecycle from data loading through cleansing, exploration, feature engineering, modelling and validation. The objective is to create a model that will predict whether an individual customer is likely to churn (output label 1) or not (output label 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's go and explore, Dora! ##\n",
    "\n",
    "Given the sample data set provided, we define \"Churn\" as the event that takes place when a user cancels their subscription, whether they are on the free or paid level of service. Let's explore whether churn volumes vary by gender or level. What we find (charts below) is that churn profile is very similar for paid and free subscribers, but male users are slightly more likely to churn.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "<img width=\"400\" src=\"https://stannnman.github.io/churn_by_level_chart.png\"/>\n",
    "        </td>\n",
    "        <td>\n",
    "<img width=\"400\" src=\"https://stannnman.github.io/churn_by_gender_chart.png\"/>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "Going a little deeper, let's look at the interactive behaviour of users and see if the page types of interest and related interaction frequencies vary for churned users versus those who stay. Now we find (chart below) the differences are much more pronounced between our two cohorts. Churned users have stronger engagement across all page types - for example, frequency of played songs is almost double for churned users than for those who stay. This discrepancy is encouraging as it suggests we have good features that we can use for churn prediction purposes.\n",
    "\n",
    "<img width=\"600\" src=\"https://stannnman.github.io/page_behaviour.png\"/>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our favourite model ##\n",
    "\n",
    "We choose three types of machine learning classification algorithms and plan to find the one that performs best:\n",
    "<ul>\n",
    "    <li>Logistic regression</li>\n",
    "    <li>Random forests</li>\n",
    "    <li>Gradient boosted trees</li>\n",
    "</ul>\n",
    "As suggested, we use the F1 score as our performance metric for comparing model performance. We choose F1 because precision and recall are both important and F1 provides a balanced combination of the two. Precision - we wish to minimise the number of false positives so we don't bear the unnecessary cost of retaining those who are unlikely to churn. Recall - we wish to minimise the number of false negatives so we don't miss candidates likely to churn and fail to intervene to retain them.\n",
    "\n",
    "We take a standard machine learning classification approach - split into train and test sets, pipeline of stages, feature scaling, K-fold cross validation with grid optimisation, evaluation of output using F1 score - all using the PySpark suite of libraries for execution.\n",
    "\n",
    "The results are listed below, showing that the **Gradient Boosted Tree** is the best performing model, followed very closely by the Random Forests model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=\"800\" src=\"https://stannnman.github.io/sparkify_results.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What next? ##\n",
    "\n",
    "We have successfully completed our first end-to-end modelling exercise, producing an optimised model that performs reasonably well at predicting which users of our music service will churn.\n",
    "\n",
    "What should we do next to improve our model?\n",
    "<ol>\n",
    "    <li>Train and test using a larger data set and leverage the scalable power of Spark on cloud infrastructure. (E.g. AWS, Google Cloud etc.)</li>\n",
    "    <li>Perform additional data exploration and feature engineering. For example, analyse more closely the behaviour in the days leading up to a churn event. Or analyse behaviour by time of day. Or look at the browser the user is using and use as a proxy for end user device.</li>\n",
    "    <li>Consider service level downgrades by users from Paid to Free as a churn event to improve the sophistication of the model.</li>\n",
    "</ol>\n",
    "    \n",
    "From a business perspective, we would like to deploy the model to production and update it regularly so we can respond quickly when likely churners are flagged. To mitigate the risk of churn, we could engage with these users, offering discounts or other incentives for them to stay. Additionally, we could perform some customer profitability analysis to ensure that retention efforts are focussed on those users whom it is profitable for us to serve. \n",
    "    \n",
    "If you'd like to dig deeper, you can find the technical details in my github repository [here](https://github.com/stannnman/dsnd_sparkify)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
